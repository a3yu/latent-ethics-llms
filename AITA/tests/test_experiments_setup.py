"""
Test Script: Verify Experiment Setup
===================================

This script verifies that all experiment modules can be imported and basic functionality works.
Run this before attempting to run the actual experiments to catch any setup issues.
"""

import sys
import os
import traceback

def test_imports():
    """Test all experiment imports."""
    print("üîç Testing experiment imports...")
    
    try:
        from experiment_1_direct_judgment import DirectJudgmentExperiment
        print("‚úÖ Experiment 1 (Direct Judgment) - Import successful")
    except Exception as e:
        print(f"‚ùå Experiment 1 - Import failed: {e}")
        return False
    
    try:
        from experiment_2_adversarial_debate import AdversarialDebateExperiment
        print("‚úÖ Experiment 2 (Adversarial Debate) - Import successful")
    except Exception as e:
        print(f"‚ùå Experiment 2 - Import failed: {e}")
        return False
    
    try:
        from experiment_3_framing_effects import FramingEffectsExperiment
        print("‚úÖ Experiment 3 (Framing Effects) - Import successful")
    except Exception as e:
        print(f"‚ùå Experiment 3 - Import failed: {e}")
        return False
    
    try:
        from experiment_4_empathy_cues import EmpathyCuesExperiment
        print("‚úÖ Experiment 4 (Empathy Cues) - Import successful")
    except Exception as e:
        print(f"‚ùå Experiment 4 - Import failed: {e}")
        return False
    
    try:
        from run_all_experiments import ExperimentRunner
        print("‚úÖ Master Runner - Import successful")
    except Exception as e:
        print(f"‚ùå Master Runner - Import failed: {e}")
        return False
    
    return True

def test_dependencies():
    """Test required dependencies."""
    print("\nüîç Testing dependencies...")
    
    required_packages = [
        'openai', 'pandas', 'matplotlib', 'seaborn', 
        'numpy', 'tenacity', 'json', 're'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"‚úÖ {package} - Available")
        except ImportError:
            print(f"‚ùå {package} - Missing")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\n‚ö†Ô∏è  Missing packages: {', '.join(missing_packages)}")
        print("Install with: pip install " + " ".join(missing_packages))
        return False
    
    return True

def test_data_file():
    """Test data file availability."""
    print("\nüîç Testing data file...")
    
    data_files = [
        'judgment_analysis_results.json',
        '../data/judgment_analysis_results.json'
    ]
    
    for data_file in data_files:
        if os.path.exists(data_file):
            file_size = os.path.getsize(data_file) / (1024 * 1024)  # MB
            print(f"‚úÖ Data file found: {data_file} ({file_size:.1f} MB)")
            return True
    
    print("‚ùå Data file not found. Expected locations:")
    for data_file in data_files:
        print(f"   - {data_file}")
    print("\nPlease ensure the AITA dataset has been processed.")
    return False

def test_api_key():
    """Test OpenAI API key availability."""
    print("\nüîç Testing API key...")
    
    api_key = os.getenv('OPENAI_API_KEY')
    if api_key:
        print(f"‚úÖ OpenAI API key found (length: {len(api_key)})")
        return True
    else:
        print("‚ùå OpenAI API key not found")
        print("Set with: export OPENAI_API_KEY='your-key-here'")
        return False

def test_basic_functionality():
    """Test basic experiment functionality without API calls."""
    print("\nüîç Testing basic functionality...")
    
    try:
        from experiment_1_direct_judgment import DirectJudgmentExperiment
        
        # Test initialization with non-existent file (should handle gracefully)
        exp = DirectJudgmentExperiment('fake_file.json')
        print("‚úÖ Experiment initialization - Working")
        
        # Test severity mapping
        severity_map = {
            'NTA': 1,
            'NAH': 2, 
            'ESH': 3,
            'YTA': 4
        }
        
        if all(isinstance(v, int) for v in severity_map.values()):
            print("‚úÖ Severity mapping - Correct")
        else:
            print("‚ùå Severity mapping - Invalid")
            return False
        
        return True
        
    except Exception as e:
        print(f"‚ùå Basic functionality test failed: {e}")
        traceback.print_exc()
        return False

def main():
    """Run all verification tests."""
    print("üß™ LLM ETHICS EXPERIMENTS - SETUP VERIFICATION")
    print("=" * 60)
    
    tests = [
        ("Dependencies", test_dependencies),
        ("Imports", test_imports),
        ("Data File", test_data_file),
        ("API Key", test_api_key),
        ("Basic Functionality", test_basic_functionality)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"‚ùå {test_name} test crashed: {e}")
            results[test_name] = False
    
    print("\n" + "=" * 60)
    print("VERIFICATION SUMMARY")
    print("=" * 60)
    
    all_passed = True
    
    for test_name, passed in results.items():
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"{status} - {test_name}")
        if not passed:
            all_passed = False
    
    if all_passed:
        print("\nüéâ All tests passed! You're ready to run the experiments.")
        print("\nNext steps:")
        print("1. Run individual experiments: python experiment_N_*.py")
        print("2. Run all experiments: python run_all_experiments.py --posts 10")
    else:
        print("\n‚ö†Ô∏è  Some tests failed. Please fix the issues above before running experiments.")
    
    return all_passed

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 